{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["!pip install evaluate\n","!pip install rouge_score"]},{"cell_type":"markdown","metadata":{},"source":["### Import Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer, BartForConditionalGeneration\n","from datasets import load_dataset,load_from_disk\n","import torch\n","import numpy as np\n","import nltk\n","from nltk.tokenize import sent_tokenize"]},{"cell_type":"markdown","metadata":{},"source":["### Preprocessing Data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["base_path = os.getcwd()\n","absolute_path = os.path.join(base_path,r'text_to_sql_data')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dataset = load_from_disk(absolute_path,keep_in_memory=True)"]},{"cell_type":"markdown","metadata":{},"source":["### Model Checkpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_checkpoint = \"facebook/bart-large-cnn\""]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["inputs = tokenizer(\"I loved reading the Hunger Games!\")\n","inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["tokenizer.convert_ids_to_tokens(inputs.input_ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["max_input_length = 512\n","max_target_length = 128\n","prefix1 = \"sql_prompt: \"\n","prefix2 = \" sql_context: \"\n","\n","\n","def preprocess_function(examples):\n","    model_inputs = tokenizer([prefix1 + prompt+prefix2+context for prompt,context in zip(examples['sql_prompt'],examples['sql_context'])],\n","        max_length=max_input_length,\n","        truncation=True,\n","    )\n","    labels = tokenizer(\n","        examples['sql'], max_length=max_target_length, truncation=True\n","    )\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["tokenized_datasets = dataset.map(preprocess_function, batched=True)"]},{"cell_type":"markdown","metadata":{},"source":["### Metric"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import evaluate\n","\n","rouge_score = evaluate.load(\"rouge\")"]},{"cell_type":"markdown","metadata":{},"source":["### Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import AutoModelForSeq2SeqLM\n","\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.generation_config.max_new_tokens = 128\n","model.generation_config.min_new_tokens = 5\n","model.config.max_new_tokens = 128\n","model.config.min_new_tokens = 5"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(model.config)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(model.generation_config)"]},{"cell_type":"markdown","metadata":{},"source":["### Data Collator"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import DataCollatorForSeq2Seq\n","\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["tokenized_datasets = tokenized_datasets.remove_columns(dataset[\"train\"].column_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["features = [tokenized_datasets[\"train\"][i] for i in range(2)]\n","data_collator(features)"]},{"cell_type":"markdown","metadata":{},"source":["### Data Loader"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","batch_size = 8\n","train_dataloader = DataLoader(\n","    tokenized_datasets[\"train\"],\n","    shuffle=True,\n","    collate_fn=data_collator,\n","    batch_size=batch_size,\n",")\n","eval_dataloader = DataLoader(\n","    tokenized_datasets[\"test\"], collate_fn=data_collator, batch_size=batch_size\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["### Optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from torch.optim import AdamW\n","\n","optimizer = AdamW(model.parameters(), lr=2e-5)"]},{"cell_type":"markdown","metadata":{},"source":["### HuggingFace Accelerator"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from accelerate import Accelerator\n","\n","accelerator = Accelerator()\n","model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n","    model, optimizer, train_dataloader, eval_dataloader\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### Optimizer Learning Rate Scheduler"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import get_scheduler\n","\n","num_train_epochs = 2\n","num_update_steps_per_epoch = len(train_dataloader)\n","num_training_steps = num_train_epochs * num_update_steps_per_epoch\n","\n","lr_scheduler = get_scheduler(\n","    \"linear\",\n","    optimizer=optimizer,\n","    num_warmup_steps=0,\n","    num_training_steps=num_training_steps,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["#### Post Processing for ROUGE computation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def postprocess_text(preds, labels):\n","    preds = [pred.strip() for pred in preds]\n","    labels = [label.strip() for label in labels]\n","\n","    # ROUGE expects a newline after each sentence\n","    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n","    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n","\n","    return preds, labels"]},{"cell_type":"markdown","metadata":{},"source":["### Training Loop"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from tqdm.auto import tqdm\n","import torch\n","import numpy as np\n","\n","progress_bar = tqdm(range(num_training_steps))\n","\n","for epoch in range(num_train_epochs):\n","    # Training\n","    model.train()\n","    for step, batch in enumerate(train_dataloader):\n","        outputs = model(**batch)\n","        loss = outputs.loss\n","        accelerator.backward(loss)\n","\n","        optimizer.step()\n","        lr_scheduler.step()\n","        optimizer.zero_grad()\n","        progress_bar.update(1)\n","        \n","\n","    # Evaluation\n","    model.eval()\n","    for step, batch in enumerate(tqdm(eval_dataloader)):\n","        with torch.no_grad():\n","            generated_tokens = accelerator.unwrap_model(model).generate(\n","                batch[\"input_ids\"],\n","                attention_mask=batch[\"attention_mask\"],\n","            )\n","\n","            generated_tokens = accelerator.pad_across_processes(\n","                generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n","            )\n","            labels = batch[\"labels\"]\n","\n","            # If we did not pad to max length, we need to pad the labels too\n","            labels = accelerator.pad_across_processes(\n","                batch[\"labels\"], dim=1, pad_index=tokenizer.pad_token_id\n","            )\n","\n","            generated_tokens = accelerator.gather(generated_tokens).cpu().numpy()\n","            labels = accelerator.gather(labels).cpu().numpy()\n","\n","            # Replace -100 in the labels as we can't decode them\n","            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","            if isinstance(generated_tokens, tuple):\n","                generated_tokens = generated_tokens[0]\n","            decoded_preds = tokenizer.batch_decode(\n","                generated_tokens, skip_special_tokens=True\n","            )\n","            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","            decoded_preds, decoded_labels = postprocess_text(\n","                decoded_preds, decoded_labels\n","            )\n","\n","            rouge_score.add_batch(predictions=decoded_preds, references=decoded_labels)\n","\n","    # Compute metrics\n","    result = rouge_score.compute()\n","    # Extract the median ROUGE scores\n","    result = {key: value * 100 for key, value in result.items()}\n","    result = {k: round(v, 4) for k, v in result.items()}\n","    print(f\"Epoch {epoch}:\", result)\n","    model.train()\n","\n","    # Save and upload\n","    output_dir = 'nl2sql_epoch'+str(epoch+1)\n","    accelerator.wait_for_everyone()\n","    unwrapped_model = accelerator.unwrap_model(model)\n","    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n","    if accelerator.is_main_process:\n","        tokenizer.save_pretrained(output_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4866003,"sourceId":8211052,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
